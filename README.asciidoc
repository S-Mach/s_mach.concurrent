s_mach.concurrent: Futures utility library
==========================================
Lance Gatlin <lance.gatlin@gmail.com>
v1,13-Jul-2014
:blogpost-status: unpublished
:blogpost-categories: s_mach, scala

*UNDER CONSTRUCTION*

image:https://travis-ci.org/S-Mach/s_mach.concurrent.svg[Build Status, link="https://travis-ci.org/S-Mach/s_mach.concurrent"]  image:https://coveralls.io/repos/S-Mach/s_mach.concurrent/badge.png[Test Coverage,link="https://coveralls.io/r/S-Mach/s_mach.concurrent"]

== Summary
+s_mach.concurrent+ is an open-source Scala library that provides concurrent execution flow control primitives for
working with the scala.concurrent standard library.

* Adds new flow control primitives +concurrently+, +serially+ and +workers+ for control of concurrent collection operations
* Adds +ScheduledExecutionContext+, a wrapper for +java.util.concurrent.ScheduledExecutorService+ that provides a functional style interface for scheduling delayed and periodic tasks
* Adds common concurrent control mechanisms such as concurrent versions of +Latch+, +Lock+, +Semaphore+ and +Queue+
* Overcomes some design limitations of the scala.concurrent library
* Provides convenience methods for writing more readable, concise and DRY concurrent code such as +Future.get+, +Future.toTry+ and +Future.fold+

== Pre-requisites
1. Scala 2.9.3, 2.10.4 or 2.11.1

== Inclusion in build.sbt
[source,sbt,numbered]
libraryDependencies += "net.s_mach" % "concurrent" %% "0.1.0"

== Links
* Code: https://github.com/S-Mach/s_mach.concurrent
* Scaladoc: http://S-Mach.github.io/s_mach.concurrent

== Imports
All code examples assume the following imports:
[source,scala,numbered]
----
import scala.util._
import scala.concurrent._
import scala.concurrent.ExecutionContext.Implicits.global
import scala.concurrent.duration._
import s_mach.concurrent._
import s_mach.concurrent.util._

case class Item(id: String, value: Int, relatedItemId: String)
def read(id: String) : Future[Item] = Future { Thread.sleep(1000); println(id); Item(id,id.toInt,(id.toInt+1).toString) }
def readFail(id: String) : Future[Item] = Future { Thread.sleep(1000); println(id); throw new RuntimeException(id.toString) }
def longRead(id: String) : Future[Item] = Future { Thread.sleep(2000); println(id); Item(id,id.toInt,(id.toInt+1).toString) }
def write(id: String, item: Item) : Future[Boolean] = Future { Thread.sleep(1000); println(id); true }
def writeFail(id: String, item: Item) : Future[Boolean] = Future { Thread.sleep(1000); println(id); throw new RuntimeException(id.toString) }
----

== Transforming and traversing collections serially and concurrently
A common task when working with futures is either transforming or traversing a collection that will call a method that
returns a future. The standard idiom for performing this task only provides methods for concurrent operation and, with
enough nesting, leads to difficult to read code:

.Example 1: Transform and traverse collections, standard method
[source,scala,numbered]
----
val oomItemIdBatch = (1 to 10).toList.map(_.toString).grouped(2).toList
val future = { // necessary for pasting into repl
  for {
    oomItem <- {
      println("Reading...")
      oomItemIdBatch
        // Serially perform read of each batch
        .foldLeft(Future.successful(List[Item]())) { (facc, idBatch) =>
          for {
            acc <- facc
            // Concurrently read batch
            oomItem <- Future.sequence(idBatch.map(read))
          } yield acc ::: oomItem
        }
    }
    _ = println("Computing...")
    oomNewItemBatch = oomItem.map(item => item.copy(value = item.value + 1)).grouped(2).toList
    oomResult <- {
      println("Writing...")
      oomNewItemBatch
        // Serially perform write of each batch
        .foldLeft(Future.successful(List[Boolean]())) { (facc, itemBatch) =>
          for {
            acc <- facc
            // Concurrently write batch
            oomResult <- Future.sequence(itemBatch.map(item => write(item.id, item)))
          } yield acc ::: oomResult
        }
    }
  } yield oomResult.forall(_ == true)
}
----

The same code, rewritten using +s_mach.concurrent+:

.Example 5: Using +s_mach.concurrent+ to serially or concurrently transform and traverse collections:
[source,scala,numbered]
----
val oomItemIdBatch = (1 to 10).toList.map(_.toString).grouped(2).toList
val future = { // necessary for pasting into repl
  for {
    oomItem <- {
      println("Reading...")
      oomItemIdBatch.serially.flatMap(_.concurrently.map(read))
    }
    _ = println("Computing...")
    oomNewItemBatch = oomItem.map(item => item.copy(value = item.value + 1)).grouped(10).toVector
    oomResult <- {
      println("Writing...")
      oomNewItemBatch.serially.flatMap(_.concurrently.map(item => write(item.id, item)))
    }
  } yield oomResult.forall(_ == true)
}
----

== Transforming and traversing collections using workers

+s_mach.concurrent+ provides the +workers+ method for controlling the amount of concurrency. The number of concurrent
workers is specified as the first parameter.

.Example 6: Using +s_mach.concurrent+ workers to transform and traverse collections:
[source,scala,numbered]
----
val oomItemIdBatch = (1 to 10).toList.map(_.toString).grouped(2).toList
val future = { // necessary for pasting into repl
  for {
    oomItem <- {
      println("Reading...")
      oomItemIdBatch.workers(2).flatMap(_.workers(4).map(read))
    }
    _ = println("Computing...")
    oomNewItemBatch = oomItem.map(item => item.copy(value = item.value + 1)).grouped(10).toVector
    oomResult <- {
      println("Writing...")
      oomNewItemBatch.workers(2).flatMap(_.workers(4).map(item => write(item.id, item)))
    }
  } yield oomResult.forall(_ == true)
}
----

== Tuple Concurrently
When first using +Future+ with a for-comprehension, it is natural to assume the following will produce concurrent
operation:

.Example 1: Incorrect +Future+ concurrency
[source,scala,numbered]
----
for {
  i1 <- read("1")
  i2 <- read("2")
  i3 <- read("3")
} yield (i1,i2,i3)
----

Sadly, this code will compile and run just fine, but it will not execute concurrently. To correctly implement concurrent
operation, the following standard pattern is used:

.Example 2: Correct +Future+ concurrency:
[source,scala,numbered]
----
val f1 = read("1")
val f2 = read("2")
val f3 = read("3")
val future = { // necessary for pasting into repl
  for {
    i1 <- f1
    i2 <- f2
    i3 <- f3
  } yield (i1,i2,i3)
}
----

To get concurrent operation, all of the futures must be started before the for-comprehension. The for-comprehension is a
monadic workflow which captures commands that must take place in a specific sequential order. The pattern in example 2
is necessary because Scala lacks an applicative workflow which captures commands that may be run in any order.
+s_mach.concurrent+ adds an applicative workflow method for futures: +concurrently+. This method can more concisely
express the pattern above:

.Example 3: New +concurrently+ method
[source,scala,numbered]
----
for {
  (i1,i2,i3) <- concurrently(read("1"), read("2"), read("3"))
} yield (i1,i2,i3)
----

In the example above, all futures are started at the same time and fed to the +concurrently+ method. The method returns
a +Future[(Int,Int,Int)]+ which completes once all supplied futures complete. After this returned Future completes, the
tuple value results can be extracted using normal Scala idioms. The +concurrently+ method also fixes problems with
+scala.concurrent+ exception handling (see the 'Under the hood: Merge' section below).

== Under the hood: +Merge+ method
Powering both the tuple +concurrently+ method and the collection +.concurrently.map+, +.concurrently.flatMap+ and
+.concurrently.foreach+ methods is the +merge+ and +flatMerge+ methods. The +merge+ method performs the same
function as +Future.sequence+ (it calls +Future.sequence+ internally) but it ensures that the returned future completes
immediately after an exception occurs in any of the futures. Because +Future.sequence+ waits on all futures in left
to right order before completing, an exception thrown at the beginning of the computation by a future at the
far right will not be detected until after all other futures have completed. For long running computations, this can
mean a significant amount of wasted time waiting on futures to complete whose results will be discarded. Also, while
the scala parallel collections correctly handle multiple concurrent exceptions, +Future.sequence+ only returns the
first exception encountered. In +Future.sequence+, all further exceptions past the first are discarded. The +merge+ and
+flatMerge+ methods fixes these problems by throwing +ConcurrentThrowable+. +ConcurrentThrowable+ has a member method to
access both the first exception thrown and a future of all exceptions thrown during the computation.

.Example 7: +Future.sequence+ gets stuck waiting on longRead to complete and only returns the first exception:
[source,scala,numbered]
----
scala> val t = Future.sequence(Vector(longRead("1"),readFail("2"),readFail("3"),read("4"))).getTry
3
4
2
1
t: scala.util.Try[scala.collection.immutable.Vector[Item]] = Failure(java.lang.RuntimeException: 2)

scala>
----

.Example 8: +merge+ method fails immediately on the first exception and throws +ConcurrentThrowable+, which can retrieve all exceptions:
[source,scala,numbered]
----
scala> val t = Vector(longRead("1"),readFail("2"),readFail("3"),read("4")).merge.getTry
2
t: scala.util.Try[scala.collection.immutable.Vector[Item]] = Failure(ConcurrentThrowable(java.lang.RuntimeException: 2))
3

scala> 4
1

scala> val allFailures = t.failed.get.asInstanceOf[ConcurrentThrowable].allFailure.get
allFailures: Vector[Throwable] = Vector(java.lang.RuntimeException: 2, java.lang.RuntimeException: 3)
----